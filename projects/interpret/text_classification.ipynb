{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "# MODEL_NAME = \"imdb-model-cnn-large.pt\"\n",
    "# MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)\n",
    "# MODEL_URL = \"https://github.com/pytorch/captum/blob/master/tutorials/models/imdb-model-cnn-large.pt\"\n",
    "# !wget -O $MODEL_PATH $MODEL_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 23.1kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 8.05MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 8.46MB/s]\n",
      "config.json: 100%|██████████| 570/570 [00:00<00:00, 5.09MB/s]\n",
      "model.safetensors: 100%|██████████| 440M/440M [00:46<00:00, 9.56MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: tensor([[-0.0400, -0.0251, -0.0267, -0.0469, -0.0344, -0.0574, -0.0384, -0.0373,\n",
      "         -0.0472, -0.0443]], grad_fn=<SumBackward1>)\n",
      "Document tokens: ['coconut', '##s', ',', 'pasta', ',', 'hawaiian', 'shirts', ',', 'pizza', '!']\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingModel:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def get_embeddings(self, text, state=\"last_hidden_state\"):\n",
    "        encoded_input = self.tokenizer(\n",
    "            text, add_special_tokens=False, return_tensors=\"pt\"\n",
    "        )\n",
    "        output = self.model(**encoded_input)\n",
    "        return output.get(state), encoded_input[\"input_ids\"]\n",
    "\n",
    "    def get_similarity(self, query_emb, doc_emb, doc_ids):\n",
    "        expand_dim = doc_emb.shape[1]\n",
    "        query_emb_exp = query_emb.unsqueeze(1).expand(-1, expand_dim, -1)\n",
    "        cos_sim = F.cosine_similarity(query_emb_exp, doc_emb, dim=-1)\n",
    "        doc_tokens = self.tokenizer.convert_ids_to_tokens(doc_ids[0])\n",
    "        return cos_sim, doc_tokens\n",
    "\n",
    "\n",
    "emb = EmbeddingModel(model, tokenizer)\n",
    "\n",
    "query = \"bottle of red wine\"\n",
    "document = \"coconuts, pasta, hawaiian shirts, pizza!\"\n",
    "\n",
    "query_emb, _ = emb.get_embeddings(query, state=\"pooler_output\")\n",
    "doc_emb, doc_ids = emb.get_embeddings(document)\n",
    "\n",
    "cos_sim, doc_tokens = emb.get_similarity(query_emb, doc_emb, doc_ids)\n",
    "print(\"Cosine similarity:\", cos_sim)\n",
    "print(\"Document tokens:\", doc_tokens)\n",
    "\n",
    "cos_sim = (\n",
    "    2 * (cos_sim - torch.min(cos_sim)) / (torch.max(cos_sim) - torch.min(cos_sim)) - 1\n",
    ")\n",
    "cos_sim_l = cos_sim.detach().numpy()[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><th></th><tr><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> coconut                    </font></mark><mark style=\"background-color: hsl(120, 75%, 50%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 55%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pasta                    </font></mark><mark style=\"background-color: hsl(120, 75%, 80%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hawaiian                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> shirts                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> pizza                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from captum.attr import visualization\n",
    "\n",
    "\n",
    "def visualize_text_x(datarecords):\n",
    "    dom = [\"<table width: 100%>\"]\n",
    "    rows = [\"<th></th>\"]\n",
    "    for datarecord in datarecords:\n",
    "        rows.append(\n",
    "            \"\".join(\n",
    "                [\n",
    "                    \"<tr>\",\n",
    "                    visualization.format_word_importances(\n",
    "                        datarecord.raw_input_ids, datarecord.word_attributions\n",
    "                    ),\n",
    "                    \"<tr>\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    dom.append(\"\".join(rows))\n",
    "    dom.append(\"</table>\")\n",
    "    html = HTML(\"\".join(dom))\n",
    "    display(html)\n",
    "\n",
    "\n",
    "vis_data_records = [\n",
    "    visualization.VisualizationDataRecord(cos_sim_l, 0, 0, 0, 0, 0, doc_tokens, 1),\n",
    "]\n",
    "visualize_text_x(vis_data_records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explainin",
   "language": "python",
   "name": "explain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
